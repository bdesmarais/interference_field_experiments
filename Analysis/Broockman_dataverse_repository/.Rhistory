spillover <- rep(NA, n)
spillover <- beta + ((1-z) * (1-beta) * exp(-tau^2 * scalar))
# This is equation 4
h.y0.z <- spillover*y.0
}
#### Transform observed outcome into uniformity trial outcome
z.to.unif <- function(z, S, y.z, beta, tau){
# z: initial treatment assignment
# S: adjacency matrix
# y.z: observed outcome vector
# beta: growth curve parameter
# tau: rate of growth parameter
scalar <- as.vector(t(z)%*%S)
spillover <- rep(NA, n)
# Equation (3)
spillover <- beta + ((1-z) * (1-beta) * exp(-tau^2 * scalar))
# This is equation 5
h.yz.0 <- (1/spillover)*y.z
return(h.yz.0)
}
#### Transform observed outcome into outcome for ANY other assignment w
z.to.w <- function(z, S, w, y.z, beta, tau){
# z: initial treatment assignment
# S: adjacency matrix
# w: new treatment assignment
# y.z: vector of outcomes for z
# beta: growth curve parameter
# tau: rate of growth parameter
scalar.z <- as.vector(t(z)%*%S)
scalar.w <- as.vector(t(w)%*%S)
spillover.z <- rep(NA, n)
spillover.z <- beta + ((1-z) * (1-beta) * exp(-tau^2 * scalar.z))
spillover.w <- rep(NA, n)
spillover.w <- beta + ((1-w) * (1-beta) * exp(-tau^2 * scalar.w))
# Below is the actual function that transforms observed outcomes into potential outcomes
# Equation (6)
h.z.to.w <- (spillover.w / spillover.z) * y.z
}
#########################################
#### Testing and p-value calculation ####
#########################################
p.val <- function(z, y.z){
cl <- makeCluster(4) #Setup for parallel computing
registerDoParallel(cl)
# Calculate the outcome vector after taking away the effect of treatment
y.0 <- z.to.unif(z=z, S=S, y.z=y.z, beta=beta, tau=tau)
# Calculate test statistic
test.stat <- ks.test(y.0[z==1], y.0[z==0],
alternative = "two.sided")$statistic
# Calculate a vector of test statistic using permutations
results <- foreach (i = 1:perms) %dopar%{
require(permute)
perm.z <- z[sample(1:length(z),length(z),rep=F)] #Each time we sample a permutation of z
perm.test.stat <- ks.test(y.0[perm.z==1], y.0[perm.z==0],
alternative = "two.sided")$statistic
}
stopCluster(cl)
# A vector of test statistics
all.test.stat.vals <- unlist(results)
# Calculating p-value
pval <- sum(all.test.stat.vals > test.stat)/perms
return(pval)
}
p.val(z=z, y.z=y.z)
cl <- makeCluster(4) #Setup for parallel computing
registerDoParallel(cl)
y.0 <- z.to.unif(z=z, S=S, y.z=y.z, beta=beta, tau=tau)
test.stat <- ks.test(y.0[z==1], y.0[z==0],
alternative = "two.sided")$statistic
results <- foreach (i = 1:perms) %dopar%{
require(permute)
perm.z <- z[sample(1:length(z),length(z),rep=F)] #Each time we sample a permutation of z
perm.test.stat <- ks.test(y.0[perm.z==1], y.0[perm.z==0],
alternative = "two.sided")$statistic
}
stopCluster(cl)
all.test.stat.vals <- unlist(results)
pval <- sum(all.test.stat.vals > test.stat)/perms
return(pval)
pval
sample(1:1125, size = 3, prob = 1/1125)
sample(1:1125, size = 3, prob = rep(x = 1/1125, 1125))
rm(list=ls())
set.seed(132)
library(doParallel)
library(foreach)
library(kSamples)
library(network)
library(permute)
n <- 70 #number of subjects
k <- 50 #number of edges
S <- matrix(NA, n, n)
temp.edge.index <- sample(c(1:n^2), size=k, replace=FALSE, prob=rep(1/n^2, n^2))
temp.edges <- rep(NA, n^2)
for (i in 1:k){
temp.edges[temp.edge.index[i]] <- 1
}
temp.edges[is.na(temp.edges)] <- 0
S <- matrix(temp.edges, n, n, byrow = TRUE)
rm(temp.edge.index)
rm(temp.edges)
network <- network(S)
plot(network)
70*70
k <- 1000 #number of edges
S <- matrix(NA, n, n)
temp.edge.index <- sample(c(1:n^2), size=k, replace=FALSE, prob=rep(1/n^2, n^2))
temp.edges <- rep(NA, n^2)
for (i in 1:k){
temp.edges[temp.edge.index[i]] <- 1
}
temp.edges[is.na(temp.edges)] <- 0
S <- matrix(temp.edges, n, n, byrow = TRUE)
rm(temp.edge.index)
rm(temp.edges)
network <- network(S)
plot(network)
cat.var <- rbinom(n = n, size = 2, prob = c(0.5, 0.5))
cat.var
cont.var <- rnorm(n, 3, sqrt(0.8))
cont.var
cov <- as.data.frame(cbind(cat.var, cont.var))
View(cov)
rm(list=ls())
set.seed(132)
library(doParallel)
library(foreach)
library(kSamples)
library(network)
library(permute)
n <- 70 #number of subjects
k <- 1000 #number of edges
k <- 500 #number of edges
S <- matrix(NA, n, n)
temp.edge.index <- sample(c(1:n^2), size=k, replace=FALSE, prob=rep(1/n^2, n^2))
temp.edges <- rep(NA, n^2)
for (i in 1:k){
temp.edges[temp.edge.index[i]] <- 1
}
temp.edges[is.na(temp.edges)] <- 0
S <- matrix(temp.edges, n, n, byrow = TRUE)
rm(temp.edge.index)
rm(temp.edges)
cat.var <- rbinom(n = n, size = 2, prob = c(0.5, 0.5))
cont.var <- rnorm(n, 3, sqrt(0.8))
cov <- as.data.frame(cbind(cat.var, cont.var))
network <- network(S, directed = FALSE, hyper = FALSE, loops = FALSE, multiple = FALSE)
set.vertex.attribute(network, names(cov), cov)
plot(network)
rm(list=ls())
set.seed(132)
library(doParallel)
library(foreach)
library(kSamples)
library(network)
library(permute)
n <- 70 #number of subjects
k <- 500 #number of edges
S <- matrix(NA, n, n)
temp.edge.index <- sample(c(1:n^2), size=k, replace=FALSE, prob=rep(1/n^2, n^2))
temp.edges <- rep(NA, n^2)
for (i in 1:k){
temp.edges[temp.edge.index[i]] <- 1
}
temp.edges[is.na(temp.edges)] <- 0
S <- matrix(temp.edges, n, n, byrow = TRUE)
rm(temp.edge.index)
rm(temp.edges)
cat.var <- rbinom(n = n, size = 2, prob = c(0.5, 0.5))
cont.var <- rnorm(n, 3, sqrt(0.8))
cov <- as.data.frame(cbind(cat.var, cont.var))
network <- network(S, directed = FALSE, hyper = FALSE, loops = FALSE, multiple = FALSE)
set.vertex.attribute(network, names(cov), cov)
library(ergm)
install.packages("ergm")
install.packages("ergm")
library(ergm)
ergm
(3*(0-1.1)^2)+(5*(1-1.1)^2)+(1*(2-1.1)^2)+(1*(4-1.1)^2)
(-1.1)^2
(-0.1)^2
0.9^2
2.9^2
8.41+0.81+3.63+0.05
sample(1:100, 10, replace = FALSE, prob = rep(0.01, 100))
(2*(0-1.9)^2)+(1*(1-1.9)^2)+(3*(2-1.9)^2)+(4*(3-1.9)^2)
(1-3.1)^2 + (3*(2-3.1)^2) + (2*(3-3.1)^2) + (2*(4-3.1)^2) + (2*(5-3.1)^2)
sqrt(1690)
pt(q = 0.025, df = 9)
qt(p = 0.025, df = 9)
hist(c(0,0,1,1,1,2,0,1,4,1))
hist(c(0,3,3,3,2,1,2,0,3,2))
sqrt(12.9/100)
1.1-(sqrt(12.9/100)*2.26)
1.1+(sqrt(12.9/100)*2.26)
sqrt(12.9*100)
1.1-(sqrt(12.9*100)*2.26)
1.1+(sqrt(12.9*100)*2.26)
110-(sqrt(12.9*100)*2.26)
110+(sqrt(12.9*100)*2.26)
1.9-(sqrt(12.9/100)*2.26)
1.9+(sqrt(12.9/100)*2.26)
sqrt(12.9*100)
190-(sqrt(12.9*100)*2.26)
190+(sqrt(12.9*100)*2.26)
qt(p = 0.05, df = 9)
310 - (1.83 * sqrt(100*16.9))
310 + (1.83 * sqrt(100*16.9))
3.1 - (1.83 * sqrt(16.9/100))
3.1 + (1.83 * sqrt(16.9/100))
274.44/4
300.44/4
75.11-9
75.11-26
1/((1000^2/(100^2*1932.657*1.96^2))+(1/100))
1/((1000^2/(100^2*1932.657*2.02^2))+(1/100))
1/((1000^2/(100^2*1932.657*2.0181^2))+(1/100))
qt(0.025,44)
1/((1000^2/(100^2*1932.657*2.0154^2))+(1/100))
((3-m)^2+(1-m)^2+(0-m)^2)/2
m <- 4/3
((3-m)^2+(1-m)^2+(0-m)^2)/2
s <- ((3-m)^2+(1-m)^2+(0-m)^2)/2
2*s/15
m <- 5/3
s <- ((3-m)^2+(1-m)^2+(1-m)^2)/2
s
2*s/15
m <- 3
s <- ((3-m)^2+(1-m)^2+(5-m)^2)/2
s
2*s/15
m <- 4/3
s <- ((3-m)^2+(0-m)^2+(1-m)^2)/2
s
2*s/15
m <- 8/3
s <- ((3-m)^2+(0-m)^2+(5-m)^2)/2
s
2*s/15
m <- 3
s <- ((3-m)^2+(1-m)^2+(5-m)^2)/2
s
2*s/15
m <- 2/3
s <- ((1-m)^2+(0-m)^2+(1-m)^2)/2
s
2*s/15
m <- 2
s <- ((1-m)^2+(0-m)^2+(5-m)^2)/2
s
2*s/15
m <- 7/3
s <- ((1-m)^2+(1-m)^2+(5-m)^2)/2
s
2*s/15
m <- 2
s <- ((0-m)^2+(1-m)^2+(5-m)^2)/2
s
2*s/15
sqrt(2.33)
sqrt(1.33)
sqrt(6.33)
sqrt(5.33)
sqrt(0.33)
sqrt(7)
2.33+1.33+4+2.33+6.33+4+0.33+7+7+5.33
7/3
sqrt(7/3)+sqrt(4/3)+2+sqrt(4/3)+sqrt(19/3)+2+sqrt(1/3)+2*sqrt(7)+sqrt(16/3)
qt(p = 0.025, 2)
(4/3) - (4.3*sqrt((2*7)/(15*3)))
(4/3) + (4.3*sqrt((2*7)/(15*3)))
(5/3) + (4.3*sqrt((2*4)/(15*3)))
c((5/3) - (4.3*sqrt((2*4)/(15*3))),
(5/3) + (4.3*sqrt((2*4)/(15*3))))
(9/3) + (4.3*sqrt((2*6)/(15*3))))
(9/3) + (4.3*sqrt((2*6)/(15*3)))
(9/3) - (4.3*sqrt((2*6)/(15*3)))
(8/3) - (4.3*sqrt((2*19)/(15*3)))
(8/3) + (4.3*sqrt((2*19)/(15*3)))
(2/3) - (4.3*sqrt((2*1)/(15*3)))
(2/3) + (4.3*sqrt((2*1)/(15*3)))
(2) + (4.3*sqrt((2*21)/(15*3)))
(2) - (4.3*sqrt((2*21)/(15*3)))
(2) - (4.3*sqrt((2*21)/(15*3)))
(7/3) - (4.3*sqrt((2*16)/(15*3)))
(7/3) + (4.3*sqrt((2*16)/(15*3)))
(0.22)*(1-0.22)*1.96^2/0.04^2
(0.22)*(1-0.22)*1.96^2/0.02^2
rm(list=ls())
gc()
set.seed(132)
setwd("~/Dropbox/Interference_in_Field_Experiments/Analysis/Broockman_dataverse_repository") #SP
library(doParallel)
library(fields)
library(foreach)
library(magic)
library(network)
library(permute)
broockman.data <- read.table("broockman_intrinsic_motivation_1.tab", sep="\t", header=TRUE)
broockman.data <- broockman.data[is.na(broockman.data$demvotepercent) == FALSE,]
permute.within.categories <- function(categories,z){
ucategories <- unique(categories)
perm.z <- rep(NA,length(z))
for(c in ucategories){
z.c <- z[which(categories==c)]
perm.z.c <- sample(z.c,length(z.c),rep=F)
perm.z[which(categories==c)] <- perm.z.c
}
perm.z
}
get.similarity <- function(x.i, x.j, y.i, y.j){ #Combination of two variables
return(sqrt((x.i-y.i)^2+(x.j-y.j)^2)) #
}
z <- broockman.data$treat_out #observed treatment
y.z <- broockman.data$code_some_response_given #observed outcome
n <- length(y.z) #number of observations
t <- length(z[z==1]) #number of treated units
perms <- 10 #number of permutations to use in generating expected exposure
perms.test <- 10 #number of permutations used in testing
adj.mat <- NA
for (i in 1:length(unique(broockman.data$leg_state))){
state.mat <- matrix(NA, nrow =length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1]), ncol = length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1]))
for (j in 1:length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1])){
for (k in 1:length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1])){
state.mat[j,k] <- get.similarity(broockman.data$demvotepercent[j], broockman.data$demvotepercent[k], broockman.data$blackpercent[j], broockman.data$blackpercent[k])
diag(state.mat) <- 0
}
}
adj.mat <- adiag(adj.mat, state.mat)
}
adj.mat <- adj.mat[-1,-1]
dim(adj.mat)
dim(broockman.data)
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
set.seed(0)
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
set.seed(10)
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
set.seed(132)
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
set.seed(123)
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
View(as.matric(cbind(num_control, num_treat)))
View(as.matrix(cbind(num_control, num_treat)))
View(perm)
View(perm[order(perm$V1, perm$V2)])
View(perm[order(V1, V2)])
View(perm[order(perm[,1], perm[,2])])
set.seed(132)
perms <- 10 #number of permutations to use in generating expected exposure
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
perms <- 50 #number of permutations to use in generating expected exposure
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
perms <- 100 #number of permutations to use in generating expected exposure
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
View(as.matrix(table(num_control)))
View(as.matrix(table(num_treat)))
rm(list=ls())
gc()
set.seed(132)
setwd("~/Dropbox/Interference_in_Field_Experiments/Analysis/Broockman_dataverse_repository") #SP
setwd("~/Dropbox/professional/Research/Active/causalityinnetworks-agenda/Interference_in_Field_Experiments/Analysis/Broockman_dataverse_repository") #BD
library(doParallel)
library(fields)
library(foreach)
library(magic)
library(network)
library(permute)
broockman.data <- read.table("broockman_intrinsic_motivation_1.tab", sep="\t", header=TRUE)
broockman.data <- broockman.data[is.na(broockman.data$demvotepercent) == FALSE,]
permute.within.categories <- function(categories,z){
ucategories <- unique(categories)
perm.z <- rep(NA,length(z))
for(c in ucategories){
z.c <- z[which(categories==c)]
perm.z.c <- sample(z.c,length(z.c),rep=F)
perm.z[which(categories==c)] <- perm.z.c
}
perm.z
}
get.similarity <- function(x.i, x.j, y.i, y.j){ #Combination of two variables
return(sqrt((x.i-y.i)^2+(x.j-y.j)^2)) #
}
z <- broockman.data$treat_out #observed treatment
y.z <- broockman.data$code_some_response_given #observed outcome
n <- length(y.z) #number of observations
t <- length(z[z==1]) #number of treated units
perms.test <- 10 #number of permutations used in testing
adj.mat <- NA
for (i in 1:length(unique(broockman.data$leg_state))){
state.mat <- matrix(NA, nrow =length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1]), ncol = length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1]))
for (j in 1:length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1])){
for (k in 1:length(broockman.data[broockman.data$leg_state==unique(broockman.data$leg_state)[i],1])){
state.mat[j,k] <- get.similarity(broockman.data$demvotepercent[j], broockman.data$demvotepercent[k], broockman.data$blackpercent[j], broockman.data$blackpercent[k])
diag(state.mat) <- 0
}
}
adj.mat <- adiag(adj.mat, state.mat)
}
adj.mat <- adj.mat[-1,-1]
dim(adj.mat)
dim(broockman.data)
perms <- 1000 #number of permutations to use in generating expected exposure
perm <- replicate(perms, permute.within.categories(broockman.data$leg_state,z))
expected.exp0 <- rep(0, n)
expected.exp1 <- rep(0, n)
for(p in 1:ncol(perm)){
#zp <- permute.within.categories(data$match_category,z)
zp <- perm[,p]
for(i in 1:n){
if (zp[i] == 1){
expected.exp1[i] <- expected.exp1[i] + sum(adj.mat[i,]*zp)
}else{
expected.exp0[i] <- expected.exp0[i] + sum(adj.mat[i,]*zp)
}
}
}
num_treat <- apply(perm,1,sum)
num_control <- apply(1-perm,1,sum)
expected.exp1 <- expected.exp1/num_treat
expected.exp0 <- expected.exp0/num_control
indirect.treatment <- function(permutation, adj.mat){ #any treatment assignment vector and adjacency matrix can be used
# permutation: can be the initial treatment assignment or a permutation
raw.exp <- rep(NA, n)
for (i in 1:n){
raw.exp[i] <- sum(adj.mat[i,]*permutation)
}
net.exp <- raw.exp - (permutation*expected.exp1 + (1-permutation)*expected.exp0)
standard.exp <- (net.exp - mean(net.exp))/sd(net.exp) #this is the spillover or indirect effect
return(standard.exp)
}
z.to.unif <- function(outcome, beta1, beta2, permutation, adj.mat){
# outcome: vector of direct treatment outcomes
# beta1: direct treatment effect parameter
# beta2: indirect treatment effect parameter
# permutation: vector of a permutation of z (can be z itself)
# adj.mat: adjacency matrix
exposure <- indirect.treatment(permutation, adj.mat)
# This is equation 5
h.yz.0 <- outcome - (beta1*permutation) - (beta2*exposure)
return(h.yz.0)
}
beta1s <- seq(from=-0.1, to=0.1, by=.1)
beta2s <- seq(from=-0.1, to=0.1, by=.1)
pvals <- matrix(NA, length(beta1s), length(beta2s))
cl <- makeCluster(4) #Setup for parallel computing
registerDoParallel(cl)
pvalues.ideology <- foreach (i = 1:length(beta1s)) %do% {
abc <- foreach (j = 1:length(beta2s)) %do% {
# Calculate the outcome vector after taking away the effect of treatment
# y.0 <- z.to.unif(outcome = y.z, beta1 = beta1s[i], beta2 = beta2s[j], permutation = z, adj.mat = S.ideo)
# Calculate observed test statistic
exposure <- indirect.treatment(permutation = z, adj.mat = adj.mat)
test.stat <- sum((lm(y.z ~ z + exposure, na.action = na.omit)$resid)^2)
# Calculate a vector of test statistic using permutations
results <- foreach (k = 1:perms.test) %dopar% {
require(permute)
perm.z <- permute.within.categories(broockman.data$leg_state,z)
perm.exposure <- indirect.treatment(permutation = perm.z, adj.mat = adj.mat)
perm.y.0 <- y.z + (-1 * beta2s[j] * indirect.treatment(permutation = z, adj.mat = adj.mat))
perm.y.0[z==1] <- perm.y.0[z==1] - beta1s[i]
y.sim <- perm.y.0 + beta1s[i]*perm.z + beta2s[j]*perm.exposure
perm.test.stat <- sum((lm(y.sim ~ perm.z + perm.exposure, na.action = na.omit)$resid)^2)
}
# A vector of test statistics
all.test.stat.vals <- as.numeric(unlist(results))
# Calculating p-value
pval <- sum(all.test.stat.vals < test.stat)/perms.test
}
as.numeric(unlist(abc))
}
stopCluster(cl)
for (i in 1:length(beta1s)){
pvals[i,] <- unlist(pvalues.ideology[i])
}
pvals #rows are direct effects, columns indirect
