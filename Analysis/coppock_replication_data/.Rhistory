}
}
# diag(S) <- 0 #Redundant since Sij=0 if Nij=0
## Visualizing the observed network
# network <- network(N)
# plot(network)
## Continuous outcome
## This depends upon treatment W and spillover S
# Currently takes the following form:
# Yi = 0.5 + 0.2*Wi + 1.65*sum(Sji) + 0.35*Wi*sum(Sji)
Y <- 0.5 + (0.2*W) + (1.65*apply(initial_S, MARGIN = 2, FUN = sum)) + (0.35*W*apply(initial_S, MARGIN = 2, FUN = sum))
####
## Question: Should i add an error to the outcome vector?
####
####
#### Required functions
####
## In this section, we create various functions
# As a first step, we create important components
# Each of them is setup for a given i, j
## Term 1: coefficient corresponding to double sum of Sij
T1 <- function(Y, W, params){
term1 <- params[ind["theta_zero"]] + params[ind["theta_one"]]*W[i]*W[j] +
params[ind["theta_two"]]*(1-W[i])*(1-W[j]) + params[ind["theta_three"]]*W[i]*(1-W[j]) -
((params[ind["beta_zero"]]*params[ind["beta_two"]] + params[ind["beta_one"]]*params[ind["beta_two"]]*W[i] +
params[ind["beta_zero"]]*params[ind["beta_three"]]*W[i] + params[ind["beta_one"]]*params[ind["beta_three"]]*W[i] -
params[ind["beta_two"]]*Y[i] + params[ind["beta_three"]]*W[i]*Y[i]) / sigma^2)
return(term1)
}
## Term 2: coefficient corresponding to sum_i(squared sum_j of S.ji)
##
## Note: this term has a multiplier (sum_k S.ki) when included in "something"
## "something" is the logit of bernoulli probability used to draw S.ji
## i.e. S.ji ~ bernoulli(p) where p = logit^-1 (something)
##
T2 <- function(W, params){
term2 <- ((-1)*(params[ind["beta_two"]]^2 + params[ind["beta_three"]]^2*W[i]^2 +
2*params[ind["beta_two"]]*params[ind["beta_three"]]*W[i])) / (2*sigma^2)
return(term2)
}
## Function to calculate MCMC draw probabilities
something <- function(j, i, r, t, Y, W, params){
#S: the matrix to use as a reference
# r is the value of current MCMC iteration
# we want to re-evaluate the probability for every i,j
# when i = j = 1, it technically takes S from the previous iteration
# for others, we use S from the same iteration
something <- T1(Y, W, params) + ((sum(S[,i,r,t])) - S[i,i,r,t] + 1)*T2(W, params) ##Multiplier for T2 needs to be checked!
return(something)
}
## Function to evaluate the log likelihood
# Written as A+B on page 24 of notes
squared_term <- function(x){
#input is the ith column of the spillover matrix of interest
t2_mult <- 0
sets <- permutations(n = length(x), r = 2, repeats.allowed = TRUE)
for(i in 1:nrow(sets)){
t2_mult <- t2_mult + prod(x[c(sets[i,])])
}
return(t2_mult)
}
log_lik <- function(params, S, Y, N, W){
r <- dim(S)[3] #Evaluate likelihood using the latest S
#Input is the matrix; must specify r and t
l <- 0
# Iteratively add to the value of log likelihood
######## ASSUMPTION: we are adding the squared term twice
for (i in 1:n){
for (j in 1:n){
value <- S[j,i]*(T1(Y, W, params)) +
(squared_term(S[,i]))*T2(W, params)
}
l <- l + value
}
return(l)
}
####
## Question: Should there be separate S.ij and S.ji?
####
####
## Setup for the EM to kickoff
####
## Initial parameters
initial_pars <- runif(8, 0, 10)
#initial_pars <- c(seq(0, 1, length.out = 4), seq(0, 1, length.out = 4))
ind <- 1:length(initial_pars)
names(ind) <- c("beta_zero", "beta_one", "beta_two", "beta_three", "theta_zero", "theta_one", "theta_two", "theta_three")
sigma <- rnorm(n = 1, mean = 3.5, sd = 0.27)
## Iterations
rep_mcmc <- 5 #number of MCMC iterations: looped over r
rep_em <- 10 #number of EM iterations: looped over t
## Turning into an array
# We would like to make S a 3D array,
# third D will track the MCMC iteration the code is at
S <- array(data = NA, dim = c(n, n, rep_mcmc+1, rep_em))
S[,,1,1] <- initial_S
## Trcking parameters
pars <- matrix(NA, rep_em+1, length(initial_pars))
pars[1,] <- initial_pars
## Arrays to track the sample averages
Sji_avg <- array(data = NA, dim = c(n,n,rep_em))
Sji_Ski_prod_avg <- array(data = NA, dim = c(n,n,rep_em)) ##Currently not tracking it, since we are assuming edge independence
# Even if we did want to separately track it, we can recycle the squared term function
## Tracking the likelihood
likelihood <- rep(NA, rep_em+1)
likelihood[1] <- log_lik(params = initial_pars, S = S[,,1,1], Y = Y, N = N, W = W) #initial likelihood
st <- Sys.time()
####
#### E-step
####
for (t in 1:rep_em){
if(t > 1){
S[,,1,t] <- S[,,dim(S)[3],t-1]
}
for (r in 1:rep_mcmc) {
iter <- r + 1
S[,,iter,t] <- S[,,r,t]
for (j in 1:n) {
for (i in 1:n) {
prob <- inv.logit(something(j = j, i = i, r = r, t = t, Y = Y, W = W, params = pars[t,]))
value <- sample(c(0,1), size = 1, prob = c(prob, 1-prob))
S[j,i,r,t] <- value
}
}
}
## Calculating averages
for(i in 1:n){
for(j in 1:n){
Sji_avg[i,j,t] <- mean(S[i,j,,t])
}
}
####
#### M-step
####
optimized <- optim(rep(0.1, 8), fn = log_lik, S = Sji_avg[,,t], Y = Y, W = W, N = N, method = "L-BFGS-B", control = list(fnscale = -1), lower = rep(-20, 8), upper = rep(20, 8))
#Updating the trackers
pars[t+1, ] <- optimized$par
likelihood[t+1] <- log_lik(params = optimized$par, S = Sji_avg[,,t], Y = Y, N = N, W = W)
}
et <- Sys.time()
et - st
#S
likelihood
pars
#
## Setup
#
rm(list=ls())
gc()
set.seed(12345)
library(igraph)
#
## Common adjacency matrix
#
# Creating adjacency matrix
adj.mat <- matrix(0, 10, 10)
adj.mat[1,2] <- adj.mat[2,1] <- 1
adj.mat[2,3] <- adj.mat[3,2] <- 1
adj.mat[2,4] <- adj.mat[4,2] <- 1
adj.mat[3,4] <- adj.mat[4,3] <- 1
adj.mat[4,5] <- adj.mat[5,4] <- 1
adj.mat[4,6] <- adj.mat[6,4] <- 1
adj.mat[5,6] <- adj.mat[6,5] <- 1
adj.mat[5,8] <- adj.mat[8,5] <- 1
adj.mat[5,9] <- adj.mat[9,5] <- 1
adj.mat[6,7] <- adj.mat[7,6] <- 1
adj.mat[7,8] <- adj.mat[8,7] <- 1
adj.mat[9,10] <- adj.mat[10,9] <- 1
#
## Plot 1: all control
#
# Assigning treatment/control to nodes as an attribute
nodes <- as.data.frame(c("C","C","C","C","C","C","C","C","C","C"))
# Defining some reference vectors for plotting
vertcols <- c("#56B4E9")
labcols <- c("black")
categories <- c("C")
vertsizes <- rep(20, nrow(adj.mat))
# Plotting
net <- graph.adjacency(adj.mat, mode = "undirected")
cols <- vertcols[match(as.character(nodes[,1]),categories)]
lcols <- labcols[match(as.character(nodes[,1]),categories)]
set.seed(5)
plot(net, vertex.color = cols, vertex.size = vertsizes,
vertex.label = as.character(nodes[,1]),
vertex.label.color = lcols, vertex.label.cex = .85,
edge.color = "black",
layout=layout.fruchterman.reingold,
main = "All control: Uniform fraudulent registration")
box(which = "plot", col = "black")
#
## Plot 2: randomly treated
#
# Assigning treatment/control to nodes as an attribute
nodes <- as.data.frame(c("C","T","C","C","C","T","C","C","T","T"))
# Defining some reference vectors for plotting
vertcols <- c("#56B4E9", "#E69F00")
labcols <- c("black", "black")
categories <- c("T", "C")
vertsizes <- rep(20, nrow(adj.mat))
vertsizes[nodes == "T"] <- 10
# Plotting
net <- graph.adjacency(adj.mat, mode = "undirected")
cols <- vertcols[match(as.character(nodes[,1]),categories)]
lcols <- labcols[match(as.character(nodes[,1]),categories)]
set.seed(5)
plot(net, vertex.color = cols, vertex.size = vertsizes,
vertex.label = as.character(nodes[,1]),
vertex.label.color = lcols, vertex.label.cex = .85,
edge.color = "black",
layout=layout.fruchterman.reingold,
main = "Randomized treatment: Fraudulent registration at control centers")
box(which = "plot", col = "black")
#
## Plot 2: Spilled over treatment
#
# Assigning treatment/control to nodes as an attribute
nodes <- as.data.frame(c("C","T","C","C","C","T","C","C","T","T"))
# Defining some reference vectors for plotting
vertcols <- c("#56B4E9", "#E69F00")
labcols <- c("black", "black")
#
## Plot 2: randomly treated
#
# Assigning treatment/control to nodes as an attribute
nodes <- as.data.frame(c("C","T","C","C","C","T","C","C","T","T"))
# Defining some reference vectors for plotting
vertcols <- c("#56B4E9", "#E69F00")
labcols <- c("black", "black")
categories <- c("T", "C")
vertsizes <- rep(20, nrow(adj.mat))
vertsizes[nodes == "T"] <- 15
# Plotting
net <- graph.adjacency(adj.mat, mode = "undirected")
cols <- vertcols[match(as.character(nodes[,1]),categories)]
lcols <- labcols[match(as.character(nodes[,1]),categories)]
set.seed(5)
plot(net, vertex.color = cols, vertex.size = vertsizes,
vertex.label = as.character(nodes[,1]),
vertex.label.color = lcols, vertex.label.cex = .85,
edge.color = "black",
layout=layout.fruchterman.reingold,
main = "Randomized treatment: Fraudulent registration at control centers")
box(which = "plot", col = "black")
#
## Plot 3: Spilled over treatment
#
# Assigning treatment/control to nodes as an attribute
nodes <- as.data.frame(c("C","T","C","C","C","T","C","C","T","T"))
# Defining some reference vectors for plotting
vertcols <- c("#56B4E9", "#E69F00")
labcols <- c("black", "black")
categories <- c("T", "C")
vertsizes <- rep(25, nrow(adj.mat))
vertsizes[nodes == "T"] <- 15
# Plotting
net <- graph.adjacency(adj.mat, mode = "undirected")
cols <- vertcols[match(as.character(nodes[,1]),categories)]
lcols <- labcols[match(as.character(nodes[,1]),categories)]
set.seed(5)
plot(net, vertex.color = cols, vertex.size = vertsizes,
vertex.label = as.character(nodes[,1]),
vertex.label.color = lcols, vertex.label.cex = .85,
edge.color = "black",
layout=layout.fruchterman.reingold,
main = "Interference: Fraudulent registration has spread")
box(which = "plot", col = "black")
library(data.table)
dat <- fread("Box Sync/DataFest/2018/DataFest 2018/datafest2018-Updated-April12.csv")
head(dat$date)
hist(head(dat$date))
install.packages("lubridate")
library(lubridate)
freqs <- aggregate(dat$date, by=list(dat$date), FUN=length)
head(dat$date)
as_date(head(dat$date))
hist(as_date(head(dat$date)))
hist(as_date(head(freqs$Group.1)))
View(freqs)
ggplot(freqs, aes(x=Group.1, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(as.Date("2006-12-01"),as.Date("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month") +
theme_bw() + opts(axis.text.x = theme_text(angle=90))
library(ggplot)
library(ggplot2)
ggplot(freqs, aes(x=Group.1, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(as.Date("2006-12-01"),as.Date("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month") +
theme_bw() + opts(axis.text.x = theme_text(angle=90))
library(scales)
ggplot(freqs, aes(x=Group.1, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(as.Date("2006-12-01"),as.Date("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month") +
theme_bw() + opts(axis.text.x = theme_text(angle=90))
ggplot(freqs, aes(x=Group.1, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(as.Date("2006-12-01"),as.Date("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month") +
theme_bw())
ggplot(freqs, aes(x=Group.1, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(as.Date("2006-12-01"),as.Date("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month")
ymd(head(freqs$Group.1))
freqs$date <- ymd(freqs$Group.1)
ggplot(freqs, aes(x=date, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(ymd("2006-12-01"),ymd("2017-11-30"))) +
ylab("Frequency") + xlab("Day, Year, and Month")
ggplot(freqs, aes(x=date, y=x)) + geom_bar(stat="identity") +
scale_x_date(breaks="1 day", labels=date_format("%Y-%m-%d"),
limits=c(ymd("2006-12-01"),ymd("2017-11-30")))
sample(1:15)
sample(1:15, size = 1, replace=FALSE)
sample(1:15, size = 1, replace=FALSE)
?clusGap
??clusGap
clupGap(dat$estimatedSalary, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
install.packages("cluster")
library(cluster)
clupGap(dat$estimatedSalary, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat$estimatedSalary, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat$estimatedSalary, FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(as.numeric(dat$estimatedSalary), FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat$estimatedSalary, FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat, FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat[,c(4,15)], FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat[1:1000,c(4,15)], FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
clusGap(dat[1:100,c(4,15)], FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
View(head(dat))
clusGap(dat[1:100,c(6,15)], FUNcluster = kmeans, K.max = 5, B = 100, d.power = 1, verbose = TRUE)
sample(1:3, 1, replace = FALSE)
dat <- fread("Box Sync/DataFest/2018/DataFest 2018/datafest2018-Updated-April12.csv")
library(data.table)
dat <- fread("Box Sync/DataFest/2018/DataFest 2018/datafest2018-Updated-April12.csv")
sample(1:7)
sample(1:8)
rm(list=ls())
gc()
## Create a function to evaluate the point estimate and confidence intervals using the grid of p-values
BFP.results.summary <- function(parameters, p.values, level){
threshold <- 1-level
estimate <- as.numeric(parameters[which.max(p.values),])
CIs <- NULL
for(p in 1:ncol(parameters)){
select.col <- 0
for(c in (1:ncol(parameters))[-p]){
select.col <- select.col + 1*(parameters[,c]==estimate[c])
}
select.col <- which(select.col==(ncol(parameters)-1))
parameters.p <- parameters[select.col,p]
p.values.p <- p.values[select.col]
parameters.p <- parameters.p[which(p.values.p>threshold)]
CIs <- rbind(CIs,c(min(parameters.p),max(parameters.p)))
}
list(estimate,CIs)
}
## Read in results of all four Bergan analyses
# Binary cohort with copartisanship
load("BerganSPPQRRresults_copartisan_cohort_binary.RData")
setwd("~/git/interference_field_experiments/Analysis/SPPQReplicationArchive")
## Read in results of all four Bergan analyses
# Binary cohort with copartisanship
load("BerganSPPQRRresults_copartisan_cohort_binary.RData")
copartisan_cohort_binary_results <- do.call('rbind',BFP.results)[,1]
rm(list=ls())
gc()
## Create a function to evaluate the point estimate and confidence intervals using the grid of p-values
BFP.results.summary <- function(parameters, p.values, level){
threshold <- 1-level
estimate <- as.numeric(parameters[which.max(p.values),])
CIs <- NULL
for(p in 1:ncol(parameters)){
select.col <- 0
for(c in (1:ncol(parameters))[-p]){
select.col <- select.col + 1*(parameters[,c]==estimate[c])
}
select.col <- which(select.col==(ncol(parameters)-1))
parameters.p <- parameters[select.col,p]
p.values.p <- p.values[select.col]
parameters.p <- parameters.p[which(p.values.p>threshold)]
CIs <- rbind(CIs,c(min(parameters.p),max(parameters.p)))
}
list(estimate,CIs)
}
## Read in results of all four Butler-Nickerson analyses
# Binary committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_binary.RData")
setwd("~/git/interference_field_experiments/Analysis/coppock_replication_data")
## Read in results of all four Butler-Nickerson analyses
# Binary committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_binary.RData")
copartisan_committee_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_weighted.RData")
copartisan_committee_weighted_results <- do.call('rbind',BFP.results)[,1]
# Binary cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_binary.RData")
copartisan_cohort_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_weighted.RData")
copartisan_cohort_weighted_results <- do.call('rbind',BFP.results)[,1]
rm(list=ls())
gc()
## Create a function to evaluate the point estimate and confidence intervals using the grid of p-values
BFP.results.summary <- function(parameters, p.values, level){
threshold <- 1-level
estimate <- as.numeric(parameters[which.max(p.values),])
CIs <- NULL
for(p in 1:ncol(parameters)){
select.col <- 0
for(c in (1:ncol(parameters))[-p]){
select.col <- select.col + 1*(parameters[,c]==estimate[c])
}
select.col <- which(select.col==(ncol(parameters)-1))
parameters.p <- parameters[select.col,p]
p.values.p <- p.values[select.col]
parameters.p <- parameters.p[which(p.values.p>threshold)]
CIs <- rbind(CIs,c(min(parameters.p),max(parameters.p)))
}
list(estimate,CIs)
}
## Read in results of all four Butler-Nickerson analyses
# Binary committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_binary.RData")
copartisan_committee_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_weighted.RData")
copartisan_committee_weighted_results <- do.call('rbind',BFP.results)[,1]
# Binary cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_binary.RData")
copartisan_cohort_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_weighted.RData")
copartisan_cohort_weighted_results <- do.call('rbind',BFP.results)[,1]
## Generate the point estimates and 90 & 95% CIs for each analysis
# Binary cohort with copartisanship
summary.cohort_binary.95 <- BFP.results.summary(parameters, copartisan_cohort_binary_results, level = 0.95)
summary.cohort_binary.9 <- BFP.results.summary(parameters, copartisan_cohort_binary_results, level = 0.9)
cohort.binary.table <- cbind(summary.cohort_binary.95[[1]], summary.cohort_binary.95[[2]], summary.cohort_binary.9[[2]])
cohort.binary <- xtable(cohort.binary.table)
print(cohort.binary, file = "butler_cohort_binary_table4_bottomleft.txt")
library(xtable)
rm(list=ls())
gc()
## Create a function to evaluate the point estimate and confidence intervals using the grid of p-values
BFP.results.summary <- function(parameters, p.values, level){
threshold <- 1-level
estimate <- as.numeric(parameters[which.max(p.values),])
CIs <- NULL
for(p in 1:ncol(parameters)){
select.col <- 0
for(c in (1:ncol(parameters))[-p]){
select.col <- select.col + 1*(parameters[,c]==estimate[c])
}
select.col <- which(select.col==(ncol(parameters)-1))
parameters.p <- parameters[select.col,p]
p.values.p <- p.values[select.col]
parameters.p <- parameters.p[which(p.values.p>threshold)]
CIs <- rbind(CIs,c(min(parameters.p),max(parameters.p)))
}
list(estimate,CIs)
}
## Read in results of all four Butler-Nickerson analyses
# Binary committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_binary.RData")
copartisan_committee_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted committee with copartisonship
load("CoppockSPPQRRresults_copartisan_committee_weighted.RData")
copartisan_committee_weighted_results <- do.call('rbind',BFP.results)[,1]
# Binary cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_binary.RData")
copartisan_cohort_binary_results <- do.call('rbind',BFP.results)[,1]
# Weighted cohort with copartisanship
load("CoppockSPPQRRresults_copartisan_cohort_weighted.RData")
copartisan_cohort_weighted_results <- do.call('rbind',BFP.results)[,1]
## Generate the point estimates and 90 & 95% CIs for each analysis
# Binary cohort with copartisanship
summary.cohort_binary.95 <- BFP.results.summary(parameters, copartisan_cohort_binary_results, level = 0.95)
summary.cohort_binary.9 <- BFP.results.summary(parameters, copartisan_cohort_binary_results, level = 0.9)
cohort.binary.table <- cbind(summary.cohort_binary.95[[1]], summary.cohort_binary.95[[2]], summary.cohort_binary.9[[2]])
cohort.binary <- xtable(cohort.binary.table)
print(cohort.binary, file = "butler_cohort_binary_table4_bottomleft.txt")
# Weighted cohort with copartisanship
summary.cohort_weighted.95 <- BFP.results.summary(parameters, copartisan_cohort_weighted_results, level = 0.95)
summary.cohort_weighted.9 <- BFP.results.summary(parameters, copartisan_cohort_weighted_results,level = 0.9)
cohort.weighted.table <- cbind(summary.cohort_weighted.95[[1]], summary.cohort_weighted.95[[2]], summary.cohort_weighted.9[[2]])
cohort.weighted<- xtable(cohort.weighted.table)
print(cohort.weighted, file = "butler_cohort_weighted_table4_bottomright.txt")
# Binary committee with copartisanship
summary.committee_binary.95 <- BFP.results.summary(parameters, copartisan_committee_binary_results, level = 0.95)
summary.committee_binary.9 <- BFP.results.summary(parameters, copartisan_committee_binary_results,level = 0.9)
committee.binary.table <- cbind(summary.committee_binary.95[[1]], summary.committee_binary.95[[2]], summary.committee_binary.9[[2]])
committee.binary <- xtable(committee.binary.table)
print(committee.binary, file = "butler_committee_binary_table4_topleft.txt")
# Weighted committee with copartisanship
summary.committee_weighted.95 <- BFP.results.summary(parameters, copartisan_committee_weighted_results, level = 0.95)
summary.committee_weighted.9 <- BFP.results.summary(parameters, copartisan_committee_weighted_results, level = 0.9)
committee.weighted.table <- cbind(summary.committee_weighted.95[[1]], summary.committee_weighted.95[[2]], summary.committee_weighted.9[[2]])
committee.weighted <- xtable(committee.weighted.table)
print(committee.weighted, file = "butler_committee_weighted_table4_topright.txt")
wd()
which(wd())
wd
getwd()
cohort.binary
cohort.weighted
committee.binary
committee.weighted
